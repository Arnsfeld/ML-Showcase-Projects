{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n",
      "Mean accuracy: 0.5990, Standard deviation of accuracy: 0.0932\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preparing Data\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error,mean_squared_log_error, roc_auc_score, accuracy_score, f1_score, precision_recall_curve, log_loss\n",
    "# Load the rock mines dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\"\n",
    "df = pd.read_csv(url)\n",
    "column_names = [\"sensor_\" + str(i) for i in range(1, 61)] + [\"target\"]\n",
    "df.columns = column_names\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={\"index\": \"id\"})\n",
    "df['target'] = df['target'].map({'M': 1, 'R': 0})\n",
    "x_data = df.iloc[:, :5]\n",
    "x_data = x_data.drop('id', axis=1)\n",
    "y_data = df['target']\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import*\n",
    "# KFold with random_state for reproducibility\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "##### Get Base Scoring\n",
    "# Cross Validation\n",
    "accuracies = []\n",
    "for train_index, test_index in kf.split(x_data):\n",
    "    x_train, x_test = x_data.iloc[train_index], x_data.iloc[test_index]\n",
    "    y_train, y_test = y_data.iloc[train_index], y_data.iloc[test_index]\n",
    "    rf.fit(x_train, y_train)\n",
    "    y_pred = rf.predict(x_test)\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "print('Baseline')\n",
    "print(f'Mean accuracy: {mean_accuracy:.4f}, Standard deviation of accuracy: {std_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing combination 14/14\n",
      "Cluster Data\n",
      "Mean accuracy: 0.8836, Standard deviation of accuracy: 0.0660\n",
      "Original Data + Cluster Data\n",
      "Mean accuracy: 0.9121, Standard deviation of accuracy: 0.0620\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "def determine_optimal_clusters(data, max_clusters=6):\n",
    "    inertia = []\n",
    "    #silhouette_avg = []\n",
    "    \n",
    "    for n in range(2, max_clusters):\n",
    "        kmeans = KMeans(n_clusters=n, n_init=10, random_state=42)\n",
    "        kmeans.fit(data)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "    \n",
    "    # Elbow Method: Find the \"elbow\" point\n",
    "    optimal_clusters = np.diff(inertia, 2).argmin() + 2\n",
    "    \n",
    "    # Silhouette Analysis: Find the maximum silhouette score\n",
    "    #optimal_clusters_silhouette = np.argmax(silhouette_avg) + 2\n",
    "    # Combine both methods to determine the optimal number of clusters\n",
    "    #optimal_clusters = max(elbow_point, optimal_clusters_silhouette)\n",
    "    return optimal_clusters\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "# Generate combinations of columns with 1 to 3 columns\n",
    "columns = x_data.columns\n",
    "combs = [list(combinations(columns, i)) for i in range(1, 4)]\n",
    "combs = [item for sublist in combs for item in sublist]\n",
    "# Initialize DataFrames to store cluster labels\n",
    "data_cluster = pd.DataFrame()\n",
    "# Set the number of clusters and K-Fold parameters\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# Process each combination of columns\n",
    "for idx, comb in enumerate(combs, start=1):\n",
    "    print(f\"Processing combination {idx}/{len(combs)}\", end=\"\\r\")\n",
    "    \n",
    "    # Initialize lists to store fold predictions\n",
    "    #fold_predictions_train = []\n",
    "    fold_predictions_test = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(x_data):\n",
    "        x_train_split = x_data.iloc[train_index].reset_index(drop=False)\n",
    "        x_test_split = x_data.iloc[test_index].reset_index(drop=False)\n",
    "        # Set the original index back\n",
    "        x_train_split.set_index('index', inplace=True)\n",
    "        x_test_split.set_index('index', inplace=True)   \n",
    "        #x_train_fold, x_test_fold = x_train.iloc[train_index], x_train.iloc[test_index]\n",
    "        x_train_subset = x_train_split[list(comb)]\n",
    "        x_test_subset = x_test_split[list(comb)]\n",
    "        \n",
    "        # Determine the optimal number of clusters\n",
    "        optimal_clusters = determine_optimal_clusters(x_train_subset)\n",
    "        \n",
    "        # Initialize and fit the K-Means model\n",
    "        kmeans = KMeans(n_clusters=optimal_clusters, n_init=10)\n",
    "        kmeans.fit(x_train_subset)\n",
    "        \n",
    "        # Store the cluster labels\n",
    "        fold_predictions_test.append(pd.Series(kmeans.predict(x_test_subset), index=x_test_split.index))\n",
    "    \n",
    "    # Concatenate fold predictions\n",
    "    feature_name = \"_\".join(comb) + \"_cluster\"\n",
    "    #data_cluster_train[feature_name] = pd.concat(fold_predictions_train).sort_index()\n",
    "    data_cluster[feature_name] = pd.concat(fold_predictions_test)\n",
    "## Reevaluate with Cluster Data only\n",
    "accuracies = []\n",
    "for train_index, test_index in kf.split(data_cluster):\n",
    "    x_train, x_test = data_cluster.iloc[train_index], data_cluster.iloc[test_index]\n",
    "    y_train, y_test = y_data.iloc[train_index], y_data.iloc[test_index]\n",
    "    rf.fit(x_train, y_train)\n",
    "    y_pred = rf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "print('')\n",
    "print('Cluster Data')\n",
    "print(f'Mean accuracy: {mean_accuracy:.4f}, Standard deviation of accuracy: {std_accuracy:.4f}')\n",
    "## Reevaluate with Cluster Data and Original Data\n",
    "x_data_enc_cluster = pd.merge(data_cluster, x_data, left_index=True, right_index=True)\n",
    "accuracies = []\n",
    "for train_index, test_index in kf.split(x_data_enc_cluster):\n",
    "    x_train, x_test = x_data_enc_cluster.iloc[train_index], x_data_enc_cluster.iloc[test_index]\n",
    "    y_train, y_test = y_data.iloc[train_index], y_data.iloc[test_index]\n",
    "    rf.fit(x_train, y_train)\n",
    "    y_pred = rf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "print('Original Data + Cluster Data')\n",
    "print(f'Mean accuracy: {mean_accuracy:.4f}, Standard deviation of accuracy: {std_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
