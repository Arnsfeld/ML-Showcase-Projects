{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-17 16:58:54,268] A new study created in memory with name: GBC_SKFold\n",
      "[I 2024-04-17 16:58:55,931] Trial 0 finished with value: 0.7020325367423114 and parameters: {'loss': 'log_loss', 'learning_rate': 0.7058394955255263, 'n_estimators': 861, 'subsample': 0.3908800056440055, 'criterion': 'friedman_mse', 'min_samples_split': 0.2420829177681204, 'min_samples_leaf': 0.5584415181899345, 'max_depth': 35, 'min_impurity_decrease': 0.9344504575307848}. Best is trial 0 with value: 0.7020325367423114.\n",
      "[I 2024-04-17 16:58:57,653] Trial 1 finished with value: 0.6953992449689483 and parameters: {'loss': 'exponential', 'learning_rate': 0.7036115370728723, 'n_estimators': 892, 'subsample': 0.4156282770518035, 'criterion': 'friedman_mse', 'min_samples_split': 0.6641083012779623, 'min_samples_leaf': 0.863649525682642, 'max_depth': 33, 'min_impurity_decrease': 0.907374954254645}. Best is trial 1 with value: 0.6953992449689483.\n",
      "[I 2024-04-17 16:58:58,432] Trial 2 finished with value: 0.7039362600550672 and parameters: {'loss': 'log_loss', 'learning_rate': 0.4660363890148854, 'n_estimators': 398, 'subsample': 0.174037912247909, 'criterion': 'squared_error', 'min_samples_split': 0.5085645239749814, 'min_samples_leaf': 0.38213000614371007, 'max_depth': 39, 'min_impurity_decrease': 0.2292798072382245}. Best is trial 1 with value: 0.6953992449689483.\n",
      "[I 2024-04-17 16:58:58,754] Trial 3 finished with value: 0.743444976859679 and parameters: {'loss': 'exponential', 'learning_rate': 0.8179600239986063, 'n_estimators': 144, 'subsample': 0.14808105320430742, 'criterion': 'squared_error', 'min_samples_split': 0.16849868138163082, 'min_samples_leaf': 0.5720789420025103, 'max_depth': 38, 'min_impurity_decrease': 0.08091910842580874}. Best is trial 1 with value: 0.6953992449689483.\n",
      "[I 2024-04-17 16:59:00,017] Trial 4 finished with value: 0.6915724064509545 and parameters: {'loss': 'log_loss', 'learning_rate': 0.22386253550926527, 'n_estimators': 161, 'subsample': 0.9920365240779694, 'criterion': 'squared_error', 'min_samples_split': 0.2803797623305214, 'min_samples_leaf': 0.13831788820336943, 'max_depth': 20, 'min_impurity_decrease': 0.7657123913610582}. Best is trial 4 with value: 0.6915724064509545.\n",
      "[I 2024-04-17 16:59:01,249] Trial 5 finished with value: 0.6947106574155459 and parameters: {'loss': 'log_loss', 'learning_rate': 0.5998410220215075, 'n_estimators': 642, 'subsample': 0.5163566320376198, 'criterion': 'friedman_mse', 'min_samples_split': 0.919403698455438, 'min_samples_leaf': 0.29546472315433536, 'max_depth': 49, 'min_impurity_decrease': 0.5419327463089687}. Best is trial 4 with value: 0.6915724064509545.\n",
      "[I 2024-04-17 16:59:01,863] Trial 6 finished with value: 0.6916797240151847 and parameters: {'loss': 'exponential', 'learning_rate': 0.09816719964776421, 'n_estimators': 302, 'subsample': 0.9415142954334416, 'criterion': 'friedman_mse', 'min_samples_split': 0.09739153635704567, 'min_samples_leaf': 0.8420331205925108, 'max_depth': 46, 'min_impurity_decrease': 0.5265615745688733}. Best is trial 4 with value: 0.6915724064509545.\n",
      "[I 2024-04-17 16:59:05,659] Trial 7 finished with value: 0.5532892029053634 and parameters: {'loss': 'log_loss', 'learning_rate': 0.8831200035382035, 'n_estimators': 588, 'subsample': 0.8860679407504498, 'criterion': 'friedman_mse', 'min_samples_split': 0.7628282682965966, 'min_samples_leaf': 0.20237310060863545, 'max_depth': 27, 'min_impurity_decrease': 0.3935119362487157}. Best is trial 7 with value: 0.5532892029053634.\n",
      "[I 2024-04-17 16:59:06,655] Trial 8 finished with value: 0.6914734584873854 and parameters: {'loss': 'log_loss', 'learning_rate': 0.057095710982950854, 'n_estimators': 512, 'subsample': 0.2654714812131883, 'criterion': 'friedman_mse', 'min_samples_split': 0.6471561277693758, 'min_samples_leaf': 0.1787501062620679, 'max_depth': 28, 'min_impurity_decrease': 0.028542373207816496}. Best is trial 7 with value: 0.5532892029053634.\n",
      "[I 2024-04-17 16:59:09,188] Trial 9 finished with value: 0.4435909590351555 and parameters: {'loss': 'exponential', 'learning_rate': 0.017993897984345253, 'n_estimators': 623, 'subsample': 0.19822337824608738, 'criterion': 'friedman_mse', 'min_samples_split': 0.06579724879252746, 'min_samples_leaf': 0.037237155972717484, 'max_depth': 10, 'min_impurity_decrease': 0.169449388843099}. Best is trial 9 with value: 0.4435909590351555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4435909590351555\n",
      "{'loss': 'exponential', 'learning_rate': 0.017993897984345253, 'n_estimators': 623, 'subsample': 0.19822337824608738, 'criterion': 'friedman_mse', 'min_samples_split': 0.06579724879252746, 'min_samples_leaf': 0.037237155972717484, 'max_depth': 10, 'min_impurity_decrease': 0.169449388843099}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import*\n",
    "import optuna\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "# load dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\"\n",
    "dataset = read_csv(url, header=None)\n",
    "data = dataset.values\n",
    "x_data, y_data = data[:, :-1],data[:, -1]\n",
    "x_data = pd.DataFrame(x_data.astype('float64'))\n",
    "#Label Encoding Target\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_data)\n",
    "y_data = le.transform(y_data)\n",
    "y_data = pd.DataFrame(y_data.astype('float64'))\n",
    "##compare a validation set with the kfold output from optuna \n",
    "features, test_features, target, test_target = train_test_split(x_data, y_data, test_size=0.3, random_state=17)\n",
    "#compare set\n",
    "predictions_per_trial = dict()\n",
    "def objective(trial):\n",
    "    #Define Hyperparameter Search Space\n",
    "    params_optuna = {\n",
    "        \"loss\" :  trial.suggest_categorical(\"loss\", [\"log_loss\", \"exponential\"]),\n",
    "        \"learning_rate\" : trial.suggest_float(\"learning_rate\", 0, 1),\n",
    "        \"n_estimators\" : trial.suggest_int(\"n_estimators\", 50, 1000),\n",
    "        \"subsample\" : trial.suggest_float(\"subsample\", 0, 1),\n",
    "        \"criterion\" :  trial.suggest_categorical(\"criterion\", [\"friedman_mse\", \"squared_error\"]),\n",
    "        \"min_samples_split\" : trial.suggest_float(\"min_samples_split\", 0, 1),\n",
    "        \"min_samples_leaf\" : trial.suggest_float(\"min_samples_leaf\", 0, 1),\n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 3, 50),\n",
    "        \"min_impurity_decrease\" : trial.suggest_float(\"min_impurity_decrease\", 0, 1)\n",
    "    }\n",
    "    \n",
    "    #KFold\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    scores = []\n",
    "    for train_index,test_index in skf.split(features,target):\n",
    "        X_train, y_train = features.iloc[train_index],target.iloc[train_index]\n",
    "        X_val, y_val = features.iloc[test_index],target.iloc[test_index]\n",
    "    \n",
    "        classifier = GradientBoostingClassifier(**params_optuna)\n",
    "        classifier.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "        y_pred = classifier.predict_proba(X_val)[:,1]\n",
    "        X_train_pred = classifier.predict_proba(X_train)[:,1]\n",
    "        y_pred_test = classifier.predict_proba(test_features)[:,1]\n",
    "        \n",
    "        score = log_loss(y_val, y_pred.astype(np.float64))\n",
    "        scores.append(score)\n",
    "        #append to compare set\n",
    "        try:\n",
    "            predictions_per_trial[trial.number].append(y_pred_test)\n",
    "        except KeyError:\n",
    "            predictions_per_trial[trial.number] = [y_pred_test]\n",
    "    \n",
    "    return np.mean(scores)\n",
    "study = optuna.create_study(study_name=\"GBC_SKFold\", direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "study_df = study.trials_dataframe()\n",
    "print(study.best_value)\n",
    "print(study.best_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
