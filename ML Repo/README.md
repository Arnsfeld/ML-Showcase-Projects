In general, machine learning algorithms aim to optimise a certain metric. Due to large and complex data it is not known a priori which algorithms and techniques perform well.
Machine Learning has a heavy exploratory component. Various methods evolved to adress the issue.

Dimensionality Reduction\\
High-dimensional data can be computional expensive and can mask crucial features. Transforming data to lower dimension reduce computational complexity and also can extract key components of features.

Ensembles\\
Various models can capture key aspects of feature interactions. So usually combining different ml models to one ensemble model will result in higher metric yield.

Feature Engineering
Combining Features in the transformation process can capture new ways of feature interactions.

Feature Selection
Feature Selection methods aim to extract valuable features for model building and discard uninformative features. It is usually performed with high-dimensional data, after excessive feature enginnering or just for tuning.

Hyperparameter Optimization
Machine Learning models come with model specific parameters, the hyperparameters. These hyperparameters can be altered and tuned in automatic ways.

Imbalanced Data
In case of imbalanced data, where one target class outweights the other, there are certain methods to adress this issue.

SpotOnCheck
Due to the explorative component in Data Science/Machine Learning it is a priori unknown which algorithm would be perform best on a given dataset.
So it is advised to test multiple different ml models to choose good models and to see how varying fundamental frameworks differ from each other.


