{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "import yfinance as yf\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import f_classif\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df_Ticker = pd.DataFrame()\n",
    "ticker_list = [\"^SPX\", \"AAPL\",\"MSFT\",\"AMZN\",\"NVDA\",\"META\",\"TSLA\",\"V\",\"UNH\",\"JPM\",\n",
    "               \"JNJ\",\"LLY\",\"WMT\",\"XOM\",\"PG\",\"AVGO\",\"MA\",\"HD\",\"ORCL\",\n",
    "               \"CVX\",\"MRK\",\"KO\",\"ABBV\",\"PEP\",\"BAC\",\"COST\",\"ADBE\",\"CRM\",\"CSCO\",\n",
    "               \"TMO\",\"MCD\",\"ACN\",\"PFE\",\"NFLX\",\"DHR\",\"ABT\",\"LIN\",\"CMCSA\",\n",
    "               \"AMD\",\"NKE\",\"TMUS\",\"DIS\",\"UPS\",\"TXN\",\"PM\",\"MS\",\"CAT\",\"NEE\",\n",
    "               \"INTC\",\"QCOM\",\"UNP\",\"VZ\",\"COP\",\"BA\",\"INTU\",\"LOW\",\"IBM\",\"BMY\",\n",
    "               \"HON\",\"DE\",\"SPGI\",\"BX\",\"RTX\",\"AMAT\",\"AXP\",\"GE\",\"SCHW\",\"SBUX\",\n",
    "               \"GS\",\"NOW\",\"MDT\",\"LMT\",\"ELV\",\"ISRG\",\"BLK\",\"BKNG\",\"SYK\",\"T\",\n",
    "               \"MDLZ\",\"ADP\",\"TJX\",\"CVS\",\"ADI\",\"GILD\",\"MMC\",\"VRTX\",\"LRCX\",\n",
    "               \"C\",\"CI\",\"ETN\",\"CB\",\"ZTS\",\"WFC\",\"SLB\",\"REGN\"]\n",
    "for i in ticker_list:\n",
    "    df_single=(yf.download([i], start=\"2015-01-01\", end=\"2023-12-31\"))\n",
    "    df_single['symbol'] = i\n",
    "    df_Ticker=pd.concat([df_Ticker, df_single], ignore_index=False)\n",
    "################## delete NaN\n",
    "df_Ticker = df_Ticker.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Report Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Evaluation Report\n",
    "def cf_matrix_generation(Prediction_Value,True_Value):\n",
    "    if Prediction_Value > 0 and True_Value > 0:\n",
    "        return \"TP\"\n",
    "    elif Prediction_Value > 0 and True_Value <= 0:\n",
    "        return \"FP\"\n",
    "    elif Prediction_Value <= 0 and True_Value <= 0:\n",
    "        return \"TN\"\n",
    "    elif Prediction_Value <= 0 and True_Value > 0:\n",
    "        return \"FN\"\n",
    "  \n",
    "def Evaluation_generation(model_data, Prediction_Value, True_Value, numeric_value):\n",
    "    model_data['cf_matrix_data'] = model_data.apply(lambda row: cf_matrix_generation(row[Prediction_Value], row[True_Value]), axis=1)\n",
    "    TP_data = model_data.loc[model_data['cf_matrix_data'] == 'TP']\n",
    "    FP_data = model_data.loc[model_data['cf_matrix_data'] == 'FP']\n",
    "    TN_data = model_data.loc[model_data['cf_matrix_data'] == 'TN']\n",
    "    FN_data = model_data.loc[model_data['cf_matrix_data'] == 'FN']\n",
    "    TP = len(TP_data)\n",
    "    FP = len(FP_data)\n",
    "    TN = len(TN_data)\n",
    "    FN = len(FN_data)\n",
    "    if TP == 0:\n",
    "        TP = np.nan\n",
    "    if FP == 0:\n",
    "        FP = np.nan\n",
    "    if TN == 0:\n",
    "        TN = np.nan\n",
    "    if FP == 0:\n",
    "        FP = np.nan\n",
    "    #####Overall\n",
    "    #Total Net Profit\n",
    "    Total_Trades = TP + FP + TN + FN\n",
    "    #Max_Drawdown\n",
    "    Percent_in_the_Market = (TP + FP + TN + FN)/model_data.index.size\n",
    "    #####Trades Long\n",
    "    Total_Winners_Long = TP\n",
    "    Precision = TP/(TP + FP)\n",
    "    Long_Ratio = (TP + FN)/(TN + FN + TP + FP)\n",
    "    Return_pct_Long = TP_data[numeric_value].sum() + FP_data[numeric_value].sum()\n",
    "    Loss_pct_Long = -FP_data[numeric_value].sum()\n",
    "    Profit_Factor_Long = Return_pct_Long/Loss_pct_Long\n",
    "    Average_Win_Long = TP_data[numeric_value].sum()/TP\n",
    "    Largest_Win_Long = TP_data[numeric_value].max()    \n",
    "    Total_Losers_Long = FP\n",
    "    Average_Loss_Long = FP_data[numeric_value].sum()/FP\n",
    "    Largest_Loss_Long = FP_data[numeric_value].min()\n",
    "    Average_Trade_Long = Return_pct_Long/(TP+FP)\n",
    "    #####Trades Short\n",
    "    Total_Winners_Short = TN\n",
    "    NPV = TN/(TN + FN)\n",
    "    Short_Ratio = (TN + FP)/(TN + FN + TP + FP)\n",
    "    Return_pct_Short = -TN_data[numeric_value].sum() - FN_data[numeric_value].sum()\n",
    "    Loss_pct_Short = FN_data[numeric_value].sum()\n",
    "    Profit_Factor_Short = Return_pct_Short/Loss_pct_Short\n",
    "    #Gross Profit\n",
    "    Average_Win_Short = -(TN_data[numeric_value].sum())/TN\n",
    "    Largest_Win_Short = -TN_data[numeric_value].min()       \n",
    "    Total_Losers_Short = FN\n",
    "    Average_Loss_Short = -FN_data[numeric_value].sum()/FN\n",
    "    Largest_Loss_Short = -FN_data[numeric_value].max()\n",
    "    Average_Trade_Short = Return_pct_Short/(TN+FN)   \n",
    "#####Overall\n",
    "    Total_Winners = TP + TN\n",
    "    Accuracy = (TP + TN)/(TP + TN + FN + FP)\n",
    "    Return_pct_lin = Return_pct_Long + Return_pct_Short    \n",
    "    Total_Losers = FP + FN  \n",
    "    Average_Trade = Return_pct_lin/Total_Trades\n",
    "    Trade_Profit_Factor = (Return_pct_Long + Return_pct_Short)/(Loss_pct_Long + Loss_pct_Short)\n",
    "    data=[['Overview','Overview'],['Accuracy',Accuracy],['Precision',Precision],['NPV',NPV],['Return pct lin',Return_pct_lin],\n",
    "    ['Trade Profit Factor', Trade_Profit_Factor],['Average_Trade',Average_Trade],['Average Trade Long',Average_Trade_Long],\n",
    "    ['Average Trade Short',Average_Trade_Short],\n",
    "    ['Total Trades',Total_Trades],['Percent in the Market',Percent_in_the_Market],['Long Trades','Long Trades'],\n",
    "    ['Total Winners Long' ,Total_Winners_Long],['Precision',Precision],['Long Ratio',Long_Ratio],['Return pc long',Return_pct_Long],\n",
    "    ['Profit Factor Long',Profit_Factor_Long],['Average Trade Long',Average_Trade_Long],['Avergage Win Long',Average_Win_Long],\n",
    "    ['Average Loss Long',Average_Loss_Long],\n",
    "    ['Largest Win Long',Largest_Win_Long],['Total Losers Long',Total_Losers_Long],['Largest Loss Long',Largest_Loss_Long ],\n",
    "    ['Short Trades','Short Trades'],['Total Winners Short',Total_Winners_Short],['Negative Predictive Value',NPV],\n",
    "    ['Short Ratio',Short_Ratio],['Return pct Short',Return_pct_Short],['Profit Factor Short',Profit_Factor_Short],\n",
    "    ['Average Trade Short',Average_Trade_Short],['Average Win Short',Average_Win_Short],\n",
    "    ['Average Loss Short',Average_Loss_Short],['Largest Win Short',Largest_Win_Short],\n",
    "    ['Total Losers Short',Total_Losers_Short],['Largest Loss Short',Largest_Loss_Short],\n",
    "    ['Total Winners',Total_Winners],['General','General'],['Accuracy',Accuracy],['Total Losers',Total_Losers]]\n",
    "    Evaluation = pd.DataFrame(data,columns=['Metric','Value'])\n",
    "    return(Evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Feature Generation and Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####Get a Transformed Column e.g Returns\n",
    "def gettransformedOHLC(Ticker, dividend_column='Close', divisor_column = 'Close', dividend_shift = 0, divisor_shift = 1,  return_column='return_lag'):\n",
    "    transformed_values = []\n",
    "    for ticker in ticker_list:\n",
    "        df = Ticker[Ticker['symbol'] == ticker]\n",
    "        transformed_single_value = (df[dividend_column].shift(dividend_shift) / df[divisor_column].shift(divisor_shift) - 1) * 100\n",
    "        transformed_values.append(transformed_single_value)\n",
    "    Ticker[return_column] = pd.concat(transformed_values)\n",
    "    return Ticker\n",
    "##### Get a Transformed DF, e.g. Returns from all symbols\n",
    "def gettransformedOHLC_df(Ticker, dividend_column='Close', divisor_column = 'Close', dividend_shift = 0, divisor_shift = 1, column_suffix='_return'):\n",
    "    transformed_values = []\n",
    "    transformed_values = {}\n",
    "    for ticker in ticker_list:\n",
    "        df = Ticker[Ticker['symbol'] == ticker]\n",
    "        transformed_single_value = (df[dividend_column].shift(dividend_shift)/df[divisor_column].shift(divisor_shift)-1)*100\n",
    "        transformed_values[f'{ticker}{column_suffix}'] = transformed_single_value\n",
    "    transformed_values_df = pd.DataFrame(transformed_values)\n",
    "    Ticker = pd.merge(Ticker, transformed_values_df, on=\"Date\", how='left')\n",
    "    return Ticker\n",
    "##### Get Sum of column, e.g. Returns\n",
    "def getsum_column(Ticker, column_to_sum='Returns', column_name_new = 'sumreturns'):\n",
    "    Ticker[column_name_new] = Ticker.groupby('Date')[column_to_sum].transform('sum')\n",
    "    return Ticker\n",
    "#####Copy Data\n",
    "def create_copy_data(data):\n",
    "    data_copy = data.copy()\n",
    "    return data_copy\n",
    "#####Categorize Column\n",
    "def simpleCat(x):\n",
    "    if x > 0:\n",
    "        return int(1)\n",
    "    if x < 0:\n",
    "        return int(0)\n",
    "def apply_simpleCat(Ticker, column_name):\n",
    "    Ticker[f'{column_name}Cat'] = [simpleCat(x) for x in Ticker[column_name].values]\n",
    "    return Ticker\n",
    "#####Filter Dataframe\n",
    "def filter_by_symbol(Ticker, symbol):\n",
    "    return Ticker[Ticker['symbol'] == symbol]\n",
    "######Delete nan\n",
    "def delete_nan(Ticker):\n",
    "    Ticker = Ticker.dropna()\n",
    "    return Ticker\n",
    "#####Delete OHLC\n",
    "def delete_OHLC(Ticker):\n",
    "    del Ticker['Open']\n",
    "    del Ticker['High']\n",
    "    del Ticker['Low']\n",
    "    del Ticker['Close']\n",
    "    del Ticker['Volume']\n",
    "    del Ticker['Adj Close']\n",
    "    del Ticker['symbol']\n",
    "    return Ticker\n",
    "#####Delete Specific Column\n",
    "def delete_spec_col(Ticker, column_name):\n",
    "    del Ticker[column_name]\n",
    "    return Ticker\n",
    "#####Train/Val Split\n",
    "def split_data_train_val(df, **kwargs):\n",
    "    df_1 = df[(df.index > kwargs['start_date_train']) & (df.index < kwargs['end_date_train'])]\n",
    "    df_2 = df[(df.index > kwargs['start_date_val']) & (df.index < kwargs['end_date_val'])]\n",
    "    return df_1, df_2\n",
    "##### Prepare Model for ML\n",
    "def prepare_model_data(data, col1, col2):\n",
    "    x_data = data.drop(columns=[col1, col2])\n",
    "    y_data = pd.DataFrame(data[col2])\n",
    "    eval_data = pd.DataFrame(data[[col1, col2]])\n",
    "    return x_data, y_data, eval_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Classifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def train_classifier_ts(x_data, y_data, eval_data, n_splits, max_train_size):\n",
    "    merged_data_list = []\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits, max_train_size=max_train_size)\n",
    "    for train_index, test_index in tscv.split(x_data):\n",
    "        X_train, X_test = x_data.iloc[train_index], x_data.iloc[test_index]\n",
    "        y_train, y_test = y_data.iloc[train_index], y_data.iloc[test_index]\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        predictions = pd.DataFrame(y_pred, index=X_test.index, columns=['pred'])\n",
    "        merged_data_list.append(pd.merge(predictions, eval_data, left_index=True, right_index=True))\n",
    "    model_data_train_eval_data = pd.concat(merged_data_list)\n",
    "    return model_data_train_eval_data, model\n",
    "def evaluate_classifier_ts(x_data_val, eval_data, model):\n",
    "    eval_data['pred'] = model.predict(x_data_val)\n",
    "    model_data_val_eval_data = eval_data\n",
    "    return model_data_val_eval_data\n",
    "##### Manual Classifier\n",
    "def classifier_manual(acutal_value, threshhold_high, threshold_low):\n",
    "    if acutal_value > threshhold_high:\n",
    "        return 1\n",
    "    if acutal_value < threshold_low:\n",
    "        return 0\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline RF Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = \"Baseline_RF_ts\"\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('data_copy', FunctionTransformer(create_copy_data, validate=False)),\n",
    "    ('getReturns', FunctionTransformer(gettransformedOHLC, validate=False, kw_args={'dividend_column': 'Close', 'divisor_column': 'Close', 'dividend_shift' : 0,\n",
    "                                                                                          'divisor_shift' : 1, 'return_column': 'Returns' })),\n",
    "    ('getReturns_lag1_df', FunctionTransformer(gettransformedOHLC_df, validate=False, kw_args={'dividend_column': 'Close', 'divisor_column': 'Close', 'dividend_shift' : 1,\n",
    "                                                                                          'divisor_shift' : 2, 'column_suffix' : '_Returns_lag1' })),\n",
    "    ('filter_by_symbol', FunctionTransformer(filter_by_symbol, validate=False, kw_args={'symbol': '^SPX'})),\n",
    "    ('apply_simpleCat', FunctionTransformer(apply_simpleCat, validate=False, kw_args={'column_name': 'Returns'})),\n",
    "    ('delete_nan', FunctionTransformer(delete_nan, validate=False)),\n",
    "    ('delete_OHLC', FunctionTransformer(delete_OHLC, validate=False)),\n",
    "    ('split_data_train_val', FunctionTransformer(split_data_train_val,\n",
    "     kw_args={'start_date_train': '2015-01-01', 'end_date_train': '2022-12-31', 'start_date_val': '2023-01-01', 'end_date_val': '2023-12-31'}))\n",
    "])\n",
    "\n",
    "locals()[f\"model_data_train_{strategy}\"], locals()[f\"model_data_val_{strategy}\"] = pipeline.fit_transform(df_Ticker)\n",
    "locals()[f\"x_data_{strategy}\"], locals()[f\"y_data_{strategy}\"], locals()[f\"eval_data_{strategy}\"] = prepare_model_data(locals()[f\"model_data_train_{strategy}\"], 'Returns', 'ReturnsCat')\n",
    "locals()[f\"model_data_train_eval_data_{strategy}\"], locals()[f\"model_{strategy}\"] = train_classifier_ts(locals()[f\"x_data_{strategy}\"], locals()[f\"y_data_{strategy}\"],locals()[f\"eval_data_{strategy}\"], 10, 250)\n",
    "locals()[f\"Evaluation_report_train_{strategy}\"] = Evaluation_generation(locals()[f\"model_data_train_eval_data_{strategy}\"], 'pred', 'ReturnsCat', 'Returns')\n",
    "\n",
    "locals()[f\"x_data_val_{strategy}\"], locals()[f\"y_data_val_{strategy}\"], locals()[f\"eval_data_val_{strategy}\"] = prepare_model_data(locals()[f\"model_data_val_{strategy}\"], 'Returns', 'ReturnsCat')\n",
    "locals()[f\"model_data_val_eval_data_{strategy}\"] = evaluate_classifier_ts(locals()[f\"x_data_val_{strategy}\"], locals()[f\"eval_data_val_{strategy}\"], locals()[f\"model_{strategy}\"])\n",
    "locals()[f\"Evaluation_report_val_{strategy}\"] = Evaluation_generation(locals()[f\"model_data_val_eval_data_{strategy}\"], 'pred', 'ReturnsCat', 'Returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data Evaluation (2015-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Metric         Value\n",
      "0                    Overview      Overview\n",
      "1                    Accuracy      0.528571\n",
      "2                   Precision      0.549876\n",
      "3                         NPV      0.485997\n",
      "4              Return pct lin     75.431902\n",
      "5         Trade Profit Factor      0.114421\n",
      "6               Average_Trade      0.041446\n",
      "7          Average Trade Long       0.06356\n",
      "8         Average Trade Short     -0.002744\n",
      "9                Total Trades          1820\n",
      "10      Percent in the Market           1.0\n",
      "11                Long Trades   Long Trades\n",
      "12         Total Winners Long           667\n",
      "13                  Precision      0.549876\n",
      "14                 Long Ratio      0.537912\n",
      "15             Return pc long     77.097754\n",
      "16         Profit Factor Long      0.165088\n",
      "17         Average Trade Long       0.06356\n",
      "18          Avergage Win Long      0.815752\n",
      "19          Average Loss Long     -0.855328\n",
      "20           Largest Win Long      9.382774\n",
      "21          Total Losers Long           546\n",
      "22          Largest Loss Long    -11.984055\n",
      "23               Short Trades  Short Trades\n",
      "24        Total Winners Short           295\n",
      "25  Negative Predictive Value      0.485997\n",
      "26                Short Ratio      0.462088\n",
      "27           Return pct Short     -1.665852\n",
      "28        Profit Factor Short     -0.008666\n",
      "29        Average Trade Short     -0.002744\n",
      "30          Average Win Short      0.646006\n",
      "31         Average Loss Short     -0.616146\n",
      "32          Largest Win Short      5.183076\n",
      "33         Total Losers Short           312\n",
      "34         Largest Loss Short     -2.715726\n",
      "35              Total Winners           962\n",
      "36                    General       General\n",
      "37                   Accuracy      0.528571\n",
      "38               Total Losers           858\n"
     ]
    }
   ],
   "source": [
    "print(Evaluation_report_train_Baseline_RF_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Data Validation Set (2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Metric         Value\n",
      "0                    Overview      Overview\n",
      "1                    Accuracy         0.512\n",
      "2                   Precision      0.544379\n",
      "3                         NPV      0.444444\n",
      "4              Return pct lin      8.409253\n",
      "5         Trade Profit Factor        0.1096\n",
      "6               Average_Trade      0.033637\n",
      "7          Average Trade Long      0.091603\n",
      "8         Average Trade Short     -0.087304\n",
      "9                Total Trades           250\n",
      "10      Percent in the Market           1.0\n",
      "11                Long Trades   Long Trades\n",
      "12         Total Winners Long            92\n",
      "13                  Precision      0.544379\n",
      "14                 Long Ratio         0.548\n",
      "15             Return pc long     15.480888\n",
      "16         Profit Factor Long      0.320132\n",
      "17         Average Trade Long      0.091603\n",
      "18          Avergage Win Long      0.693899\n",
      "19          Average Loss Long     -0.628024\n",
      "20           Largest Win Long      2.284078\n",
      "21          Total Losers Long            77\n",
      "22          Largest Loss Long     -2.004123\n",
      "23               Short Trades  Short Trades\n",
      "24        Total Winners Short            36\n",
      "25  Negative Predictive Value      0.444444\n",
      "26                Short Ratio         0.452\n",
      "27           Return pct Short     -7.071634\n",
      "28        Profit Factor Short     -0.249273\n",
      "29        Average Trade Short     -0.087304\n",
      "30          Average Win Short      0.591594\n",
      "31         Average Loss Short     -0.630423\n",
      "32          Largest Win Short      1.581086\n",
      "33         Total Losers Short            45\n",
      "34         Largest Loss Short      -1.89184\n",
      "35              Total Winners           128\n",
      "36                    General       General\n",
      "37                   Accuracy         0.512\n",
      "38               Total Losers           122\n"
     ]
    }
   ],
   "source": [
    "print(Evaluation_report_val_Baseline_RF_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = \"Feature_Selection_kbest\"\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('data_copy', FunctionTransformer(create_copy_data, validate=False)),\n",
    "    ('getReturns', FunctionTransformer(gettransformedOHLC, validate=False, kw_args={'dividend_column': 'Close', 'divisor_column': 'Close', 'dividend_shift' : 0,\n",
    "                                                                                          'divisor_shift' : 1, 'return_column': 'Returns' })),\n",
    "    ('getReturns_lag1_df', FunctionTransformer(gettransformedOHLC_df, validate=False, kw_args={'dividend_column': 'Close', 'divisor_column': 'Close', 'dividend_shift' : 1,\n",
    "                                                                                          'divisor_shift' : 2, 'column_suffix' : '_Returns_lag1' })),\n",
    "    ('filter_by_symbol', FunctionTransformer(filter_by_symbol, validate=False, kw_args={'symbol': '^SPX'})),\n",
    "    ('apply_simpleCat', FunctionTransformer(apply_simpleCat, validate=False, kw_args={'column_name': 'Returns'})),\n",
    "    ('delete_nan', FunctionTransformer(delete_nan, validate=False)),\n",
    "    ('delete_OHLC', FunctionTransformer(delete_OHLC, validate=False)),\n",
    "    ('split_data_train_val', FunctionTransformer(split_data_train_val,\n",
    "     kw_args={'start_date_train': '2015-01-01', 'end_date_train': '2022-12-31', 'start_date_val': '2023-01-01', 'end_date_val': '2023-12-31'}))\n",
    "])\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import f_classif\n",
    "locals()[f\"model_data_train_{strategy}\"], locals()[f\"model_data_val_{strategy}\"] = pipeline.fit_transform(df_Ticker)\n",
    "locals()[f\"x_data_{strategy}\"], locals()[f\"y_data_{strategy}\"], locals()[f\"eval_data_{strategy}\"] = prepare_model_data(locals()[f\"model_data_train_{strategy}\"], 'Returns', 'ReturnsCat') \n",
    "fs = SelectKBest(score_func=f_classif, k=70)\n",
    "x_data_selected = fs.fit_transform(locals()[f\"x_data_{strategy}\"], locals()[f\"y_data_{strategy}\"])\n",
    "selected_feature_indices = fs.get_support(indices=True)\n",
    "feature_names = list(locals()[f\"x_data_{strategy}\"].columns)\n",
    "top_features = [feature_names[i] for i in selected_feature_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset_RF_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = \"Subset_RF_ts\"\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('data_copy', FunctionTransformer(create_copy_data, validate=False)),\n",
    "    ('getReturns', FunctionTransformer(gettransformedOHLC, validate=False, kw_args={'dividend_column': 'Close', 'divisor_column': 'Close', 'dividend_shift' : 0,\n",
    "                                                                                          'divisor_shift' : 1, 'return_column': 'Returns' })),\n",
    "    ('getReturns_lag1_df', FunctionTransformer(gettransformedOHLC_df, validate=False, kw_args={'dividend_column': 'Close', 'divisor_column': 'Close', 'dividend_shift' : 1,\n",
    "                                                                                          'divisor_shift' : 2, 'column_suffix' : '_Returns_lag1' })),\n",
    "    ('filter_by_symbol', FunctionTransformer(filter_by_symbol, validate=False, kw_args={'symbol': '^SPX'})),\n",
    "    ('apply_simpleCat', FunctionTransformer(apply_simpleCat, validate=False, kw_args={'column_name': 'Returns'})),\n",
    "    ('delete_nan', FunctionTransformer(delete_nan, validate=False)),\n",
    "    ('delete_OHLC', FunctionTransformer(delete_OHLC, validate=False)),\n",
    "    ('split_data_train_val', FunctionTransformer(split_data_train_val,\n",
    "     kw_args={'start_date_train': '2015-01-01', 'end_date_train': '2022-12-31', 'start_date_val': '2023-01-01', 'end_date_val': '2023-12-31'}))\n",
    "])\n",
    "\n",
    "locals()[f\"model_data_train_{strategy}\"], locals()[f\"model_data_val_{strategy}\"] = pipeline.fit_transform(df_Ticker)\n",
    "locals()[f\"x_data_{strategy}\"], locals()[f\"y_data_{strategy}\"], locals()[f\"eval_data_{strategy}\"] = prepare_model_data(locals()[f\"model_data_train_{strategy}\"], 'Returns', 'ReturnsCat')\n",
    "locals()[f\"x_data_{strategy}\"] = locals()[f\"x_data_{strategy}\"][top_features]\n",
    "locals()[f\"model_data_train_eval_data_{strategy}\"], locals()[f\"model_{strategy}\"] = train_classifier_ts(locals()[f\"x_data_{strategy}\"], locals()[f\"y_data_{strategy}\"],locals()[f\"eval_data_{strategy}\"], 10, 250)\n",
    "locals()[f\"Evaluation_report_train_{strategy}\"] = Evaluation_generation(locals()[f\"model_data_train_eval_data_{strategy}\"], 'pred', 'ReturnsCat', 'Returns')\n",
    "\n",
    "locals()[f\"x_data_val_{strategy}\"], locals()[f\"y_data_val_{strategy}\"], locals()[f\"eval_data_val_{strategy}\"] = prepare_model_data(locals()[f\"model_data_val_{strategy}\"], 'Returns', 'ReturnsCat')\n",
    "locals()[f\"x_data_val_{strategy}\"] = locals()[f\"x_data_val_{strategy}\"][top_features]\n",
    "locals()[f\"model_data_val_eval_data_{strategy}\"] = evaluate_classifier_ts(locals()[f\"x_data_val_{strategy}\"], locals()[f\"eval_data_val_{strategy}\"], locals()[f\"model_{strategy}\"])\n",
    "locals()[f\"Evaluation_report_val_{strategy}\"] = Evaluation_generation(locals()[f\"model_data_val_eval_data_{strategy}\"], 'pred', 'ReturnsCat', 'Returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data Evaluation (2015-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Metric         Value\n",
      "0                    Overview      Overview\n",
      "1                    Accuracy       0.50989\n",
      "2                   Precision      0.536585\n",
      "3                         NPV      0.459588\n",
      "4              Return pct lin     57.082489\n",
      "5         Trade Profit Factor      0.085399\n",
      "6               Average_Trade      0.031364\n",
      "7          Average Trade Long      0.057126\n",
      "8         Average Trade Short      -0.01718\n",
      "9                Total Trades          1820\n",
      "10      Percent in the Market           1.0\n",
      "11                Long Trades   Long Trades\n",
      "12         Total Winners Long           638\n",
      "13                  Precision      0.536585\n",
      "14                 Long Ratio      0.537912\n",
      "15             Return pc long     67.923047\n",
      "16         Profit Factor Long      0.150994\n",
      "17         Average Trade Long      0.057126\n",
      "18          Avergage Win Long      0.811538\n",
      "19          Average Loss Long     -0.816403\n",
      "20           Largest Win Long      9.382774\n",
      "21          Total Losers Long           551\n",
      "22          Largest Loss Long    -11.984055\n",
      "23               Short Trades  Short Trades\n",
      "24        Total Winners Short           290\n",
      "25  Negative Predictive Value      0.459588\n",
      "26                Short Ratio      0.462088\n",
      "27           Return pct Short    -10.840559\n",
      "28        Profit Factor Short     -0.049595\n",
      "29        Average Trade Short      -0.01718\n",
      "30          Average Win Short      0.716354\n",
      "31         Average Loss Short     -0.641007\n",
      "32          Largest Win Short       7.59697\n",
      "33         Total Losers Short           341\n",
      "34         Largest Loss Short     -3.150119\n",
      "35              Total Winners           928\n",
      "36                    General       General\n",
      "37                   Accuracy       0.50989\n",
      "38               Total Losers           892\n"
     ]
    }
   ],
   "source": [
    "print(Evaluation_report_train_Subset_RF_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Data Validation Set (2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Metric         Value\n",
      "0                    Overview      Overview\n",
      "1                    Accuracy         0.512\n",
      "2                   Precision      0.548387\n",
      "3                         NPV      0.452632\n",
      "4              Return pct lin     18.361014\n",
      "5         Trade Profit Factor      0.255899\n",
      "6               Average_Trade      0.073444\n",
      "7          Average Trade Long      0.131979\n",
      "8         Average Trade Short     -0.022061\n",
      "9                Total Trades           250\n",
      "10      Percent in the Market           1.0\n",
      "11                Long Trades   Long Trades\n",
      "12         Total Winners Long            85\n",
      "13                  Precision      0.548387\n",
      "14                 Long Ratio         0.548\n",
      "15             Return pc long     20.456768\n",
      "16         Profit Factor Long      0.487939\n",
      "17         Average Trade Long      0.131979\n",
      "18          Avergage Win Long      0.733901\n",
      "19          Average Loss Long     -0.598927\n",
      "20           Largest Win Long      2.284078\n",
      "21          Total Losers Long            70\n",
      "22          Largest Loss Long     -2.004123\n",
      "23               Short Trades  Short Trades\n",
      "24        Total Winners Short            43\n",
      "25  Negative Predictive Value      0.452632\n",
      "26                Short Ratio         0.452\n",
      "27           Return pct Short     -2.095754\n",
      "28        Profit Factor Short     -0.070266\n",
      "29        Average Trade Short     -0.022061\n",
      "30          Average Win Short      0.644893\n",
      "31         Average Loss Short      -0.57358\n",
      "32          Largest Win Short      1.640093\n",
      "33         Total Losers Short            52\n",
      "34         Largest Loss Short      -1.89184\n",
      "35              Total Winners           128\n",
      "36                    General       General\n",
      "37                   Accuracy         0.512\n",
      "38               Total Losers           122\n"
     ]
    }
   ],
   "source": [
    "print(Evaluation_report_val_Subset_RF_ts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
