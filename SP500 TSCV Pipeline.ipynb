{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentions:\\\n",
    "I want to perform a classification task to get the direction of the S&P500 for the next day.\n",
    "As input features i take the returns of the last day from some of the best capitalized stocks inside the S&P500.\n",
    "The raw data will be fetched via the Yahoo finance API.\n",
    "\n",
    "The classification model will be a simply Support Vector Classifier, the data will be very noisy\n",
    "so more complex classfiers are not recommended.\n",
    "\n",
    "For evaluation i will be perform a TimeSeriesCV with a moving window of one year (250d). The input data ranges from 2015-2022 for the training data\n",
    "analyzed with the TimeSeriesCV and also the validation data as a holdout set will be the year 2023.\n",
    "\n",
    "The Evaluation Report contains classic metrics for classification task like precision and accurcay, but also decision\n",
    "making data for a trading system like the total returns or the return per trade. Evaluation Reports will be generated for training and validation set.\n",
    "\n",
    "The data transformation (e.g. from the raw OHLC data to returns) will be done through a pipeline, additionally i set up dynamic variable naming so i am able to quickly generate different models for comparision purposes.\n",
    "\n",
    "Since i am using data with likely no significant impact on the model, i will reduce the data in a seperate model via a simply kbest approach and compare it with the Baseline mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "import yfinance as yf\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import f_classif\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df_Ticker = pd.DataFrame()\n",
    "ticker_list = [\"^SPX\", \"AAPL\",\"MSFT\",\"AMZN\",\"NVDA\",\"META\",\"TSLA\",\"V\",\"UNH\",\"JPM\",\n",
    "               \"JNJ\",\"LLY\",\"WMT\",\"XOM\",\"PG\",\"AVGO\",\"MA\",\"HD\",\"ORCL\",\n",
    "               \"CVX\",\"MRK\",\"KO\",\"ABBV\",\"PEP\",\"BAC\",\"COST\",\"ADBE\",\"CRM\",\"CSCO\",\n",
    "               \"TMO\",\"MCD\",\"ACN\",\"PFE\",\"NFLX\",\"DHR\",\"ABT\",\"LIN\",\"CMCSA\",\n",
    "               \"AMD\",\"NKE\",\"TMUS\",\"DIS\",\"UPS\",\"TXN\",\"PM\",\"MS\",\"CAT\",\"NEE\",\n",
    "               \"INTC\",\"QCOM\",\"UNP\",\"VZ\",\"COP\",\"BA\",\"INTU\",\"LOW\",\"IBM\",\"BMY\",\n",
    "               \"HON\",\"DE\",\"SPGI\",\"BX\",\"RTX\",\"AMAT\",\"AXP\",\"GE\",\"SCHW\",\"SBUX\",\n",
    "               \"GS\",\"NOW\",\"MDT\",\"LMT\",\"ELV\",\"ISRG\",\"BLK\",\"BKNG\",\"SYK\",\"T\",\n",
    "               \"MDLZ\",\"ADP\",\"TJX\",\"CVS\",\"ADI\",\"GILD\",\"MMC\",\"VRTX\",\"LRCX\",\n",
    "               \"C\",\"CI\",\"ETN\",\"CB\",\"ZTS\",\"WFC\",\"SLB\",\"REGN\"]\n",
    "for i in ticker_list:\n",
    "    df_single=(yf.download([i], start=\"2015-01-01\", end=\"2023-12-31\"))\n",
    "    df_single['symbol'] = i\n",
    "    df_Ticker=pd.concat([df_Ticker, df_single], ignore_index=False)\n",
    "################## delete NaN\n",
    "df_Ticker = df_Ticker.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Report Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Evaluation Report\n",
    "def cf_matrix_generation(Prediction_Value,True_Value):\n",
    "    if Prediction_Value > 0 and True_Value > 0:\n",
    "        return \"TP\"\n",
    "    elif Prediction_Value > 0 and True_Value <= 0:\n",
    "        return \"FP\"\n",
    "    elif Prediction_Value <= 0 and True_Value <= 0:\n",
    "        return \"TN\"\n",
    "    elif Prediction_Value <= 0 and True_Value > 0:\n",
    "        return \"FN\"\n",
    "  \n",
    "def Evaluation_generation(model_data, Prediction_Value, True_Value, numeric_value):\n",
    "    model_data['cf_matrix_data'] = model_data.apply(lambda row: cf_matrix_generation(row[Prediction_Value], row[True_Value]), axis=1)\n",
    "    TP_data = model_data.loc[model_data['cf_matrix_data'] == 'TP']\n",
    "    FP_data = model_data.loc[model_data['cf_matrix_data'] == 'FP']\n",
    "    TN_data = model_data.loc[model_data['cf_matrix_data'] == 'TN']\n",
    "    FN_data = model_data.loc[model_data['cf_matrix_data'] == 'FN']\n",
    "    TP = len(TP_data)\n",
    "    FP = len(FP_data)\n",
    "    TN = len(TN_data)\n",
    "    FN = len(FN_data)\n",
    "    if TP == 0:\n",
    "        TP = np.nan\n",
    "    if FP == 0:\n",
    "        FP = np.nan\n",
    "    if TN == 0:\n",
    "        TN = np.nan\n",
    "    if FP == 0:\n",
    "        FP = np.nan\n",
    "    #####Overall\n",
    "    #Total Net Profit\n",
    "    Total_Trades = TP + FP + TN + FN\n",
    "    #Max_Drawdown\n",
    "    Percent_in_the_Market = (TP + FP + TN + FN)/model_data.index.size\n",
    "    #####Trades Long\n",
    "    Total_Winners_Long = TP\n",
    "    Precision = TP/(TP + FP)\n",
    "    Long_Ratio = (TP + FN)/(TN + FN + TP + FP)\n",
    "    Return_pct_Long = TP_data[numeric_value].sum() + FP_data[numeric_value].sum()\n",
    "    Loss_pct_Long = -FP_data[numeric_value].sum()\n",
    "    Profit_Factor_Long = Return_pct_Long/Loss_pct_Long\n",
    "    Average_Win_Long = TP_data[numeric_value].sum()/TP\n",
    "    Largest_Win_Long = TP_data[numeric_value].max()    \n",
    "    Total_Losers_Long = FP\n",
    "    Average_Loss_Long = FP_data[numeric_value].sum()/FP\n",
    "    Largest_Loss_Long = FP_data[numeric_value].min()\n",
    "    Average_Trade_Long = Return_pct_Long/(TP+FP)\n",
    "    #####Trades Short\n",
    "    Total_Winners_Short = TN\n",
    "    NPV = TN/(TN + FN)\n",
    "    Short_Ratio = (TN + FP)/(TN + FN + TP + FP)\n",
    "    Return_pct_Short = -TN_data[numeric_value].sum() - FN_data[numeric_value].sum()\n",
    "    Loss_pct_Short = FN_data[numeric_value].sum()\n",
    "    Profit_Factor_Short = Return_pct_Short/Loss_pct_Short\n",
    "    #Gross Profit\n",
    "    Average_Win_Short = -(TN_data[numeric_value].sum())/TN\n",
    "    Largest_Win_Short = -TN_data[numeric_value].min()       \n",
    "    Total_Losers_Short = FN\n",
    "    Average_Loss_Short = -FN_data[numeric_value].sum()/FN\n",
    "    Largest_Loss_Short = -FN_data[numeric_value].max()\n",
    "    Average_Trade_Short = Return_pct_Short/(TN+FN)   \n",
    "#####Overall\n",
    "    Total_Winners = TP + TN\n",
    "    Accuracy = (TP + TN)/(TP + TN + FN + FP)\n",
    "    Return_pct_lin = Return_pct_Long + Return_pct_Short    \n",
    "    Total_Losers = FP + FN  \n",
    "    Average_Trade = Return_pct_lin/Total_Trades\n",
    "    Trade_Profit_Factor = (Return_pct_Long + Return_pct_Short)/(Loss_pct_Long + Loss_pct_Short)\n",
    "    data=[['Overview','Overview'],['Accuracy',Accuracy],['Precision',Precision],['NPV',NPV],['Return pct lin',Return_pct_lin],\n",
    "    ['Trade Profit Factor', Trade_Profit_Factor],['Average_Trade',Average_Trade],['Average Trade Long',Average_Trade_Long],\n",
    "    ['Average Trade Short',Average_Trade_Short],\n",
    "    ['Total Trades',Total_Trades],['Percent in the Market',Percent_in_the_Market],['Long Trades','Long Trades'],\n",
    "    ['Total Winners Long' ,Total_Winners_Long],['Precision',Precision],['Long Ratio',Long_Ratio],['Return pc long',Return_pct_Long],\n",
    "    ['Profit Factor Long',Profit_Factor_Long],['Average Trade Long',Average_Trade_Long],['Avergage Win Long',Average_Win_Long],\n",
    "    ['Average Loss Long',Average_Loss_Long],\n",
    "    ['Largest Win Long',Largest_Win_Long],['Total Losers Long',Total_Losers_Long],['Largest Loss Long',Largest_Loss_Long ],\n",
    "    ['Short Trades','Short Trades'],['Total Winners Short',Total_Winners_Short],['Negative Predictive Value',NPV],\n",
    "    ['Short Ratio',Short_Ratio],['Return pct Short',Return_pct_Short],['Profit Factor Short',Profit_Factor_Short],\n",
    "    ['Average Trade Short',Average_Trade_Short],['Average Win Short',Average_Win_Short],\n",
    "    ['Average Loss Short',Average_Loss_Short],['Largest Win Short',Largest_Win_Short],\n",
    "    ['Total Losers Short',Total_Losers_Short],['Largest Loss Short',Largest_Loss_Short],\n",
    "    ['Total Winners',Total_Winners],['General','General'],['Accuracy',Accuracy],['Total Losers',Total_Losers]]\n",
    "    Evaluation = pd.DataFrame(data,columns=['Metric','Value'])\n",
    "    return(Evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation and Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####Get a Transformed Column e.g Returns\n",
    "def gettransformedOHLC(Ticker, dividend_column='Close', divisor_column = 'Close', dividend_shift = 0, divisor_shift = 1,  return_column='return_lag'):\n",
    "    transformed_values = []\n",
    "    for ticker in ticker_list:\n",
    "        df = Ticker[Ticker['symbol'] == ticker]\n",
    "        transformed_single_value = (df[dividend_column].shift(dividend_shift) / df[divisor_column].shift(divisor_shift) - 1) * 100\n",
    "        transformed_values.append(transformed_single_value)\n",
    "    Ticker[return_column] = pd.concat(transformed_values)\n",
    "    return Ticker\n",
    "##### Get a Transformed DF, e.g. Returns from all symbols\n",
    "def gettransformedOHLC_df(Ticker, dividend_column='Close', divisor_column = 'Close', dividend_shift = 0, divisor_shift = 1, column_suffix='_return'):\n",
    "    transformed_values = []\n",
    "    transformed_values = {}\n",
    "    for ticker in ticker_list:\n",
    "        df = Ticker[Ticker['symbol'] == ticker]\n",
    "        transformed_single_value = (df[dividend_column].shift(dividend_shift)/df[divisor_column].shift(divisor_shift)-1)*100\n",
    "        transformed_values[f'{ticker}{column_suffix}'] = transformed_single_value\n",
    "    transformed_values_df = pd.DataFrame(transformed_values)\n",
    "    Ticker = pd.merge(Ticker, transformed_values_df, on=\"Date\", how='left')\n",
    "    return Ticker\n",
    "##### Get Sum of column, e.g. Returns\n",
    "def getsum_column(Ticker, column_to_sum='Returns', column_name_new = 'sumreturns'):\n",
    "    Ticker[column_name_new] = Ticker.groupby('Date')[column_to_sum].transform('sum')\n",
    "    return Ticker\n",
    "#####Copy Data\n",
    "def create_copy_data(data):\n",
    "    data_copy = data.copy()\n",
    "    return data_copy\n",
    "#####Categorize Column\n",
    "def simpleCat(x):\n",
    "    if x > 0:\n",
    "        return int(1)\n",
    "    if x < 0:\n",
    "        return int(0)\n",
    "def apply_simpleCat(Ticker, column_name):\n",
    "    Ticker[f'{column_name}Cat'] = [simpleCat(x) for x in Ticker[column_name].values]\n",
    "    return Ticker\n",
    "#####Filter Dataframe\n",
    "def filter_by_symbol(Ticker, symbol):\n",
    "    return Ticker[Ticker['symbol'] == symbol]\n",
    "######Delete nan\n",
    "def delete_nan(Ticker):\n",
    "    Ticker = Ticker.dropna()\n",
    "    return Ticker\n",
    "#####Delete OHLC\n",
    "def delete_OHLC(Ticker):\n",
    "    del Ticker['Open']\n",
    "    del Ticker['High']\n",
    "    del Ticker['Low']\n",
    "    del Ticker['Close']\n",
    "    del Ticker['Volume']\n",
    "    del Ticker['Adj Close']\n",
    "    del Ticker['symbol']\n",
    "    return Ticker\n",
    "#####Delete Specific Column\n",
    "def delete_spec_col(Ticker, column_name):\n",
    "    del Ticker[column_name]\n",
    "    return Ticker\n",
    "#####Train/Val Split\n",
    "def split_data_train_val(df, **kwargs):\n",
    "    df_1 = df[(df.index > kwargs['start_date_train']) & (df.index < kwargs['end_date_train'])]\n",
    "    df_2 = df[(df.index > kwargs['start_date_val']) & (df.index < kwargs['end_date_val'])]\n",
    "    return df_1, df_2\n",
    "##### Prepare Model for ML\n",
    "def prepare_model_data(data, col1, col2):\n",
    "    x_data = data.drop(columns=[col1, col2])\n",
    "    y_data = pd.DataFrame(data[col2])\n",
    "    eval_data = pd.DataFrame(data[[col1, col2]])\n",
    "    return x_data, y_data, eval_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Classifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.svm import SVC\n",
    "def train_classifier_ts(x_data, y_data, eval_data, n_splits, max_train_size):\n",
    "    merged_data_list = []\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits, max_train_size=max_train_size)\n",
    "    for train_index, test_index in tscv.split(x_data):\n",
    "        X_train, X_test = x_data.iloc[train_index], x_data.iloc[test_index]\n",
    "        y_train, y_test = y_data.iloc[train_index], y_data.iloc[test_index]\n",
    "        model =  SVC(probability=True)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        predictions = pd.DataFrame(y_pred, index=X_test.index, columns=['pred'])\n",
    "        merged_data_list.append(pd.merge(predictions, eval_data, left_index=True, right_index=True))\n",
    "    model_data_train_eval_data = pd.concat(merged_data_list)\n",
    "    return model_data_train_eval_data, model\n",
    "def evaluate_classifier_ts(x_data_val, eval_data, model):\n",
    "    eval_data['pred'] = model.predict(x_data_val)\n",
    "    model_data_val_eval_data = eval_data\n",
    "    return model_data_val_eval_data\n",
    "##### Manual Classifier\n",
    "def classifier_manual(acutal_value, threshhold_high, threshold_low):\n",
    "    if acutal_value > threshhold_high:\n",
    "        return 1\n",
    "    if acutal_value < threshold_low:\n",
    "        return 0\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline SVC Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = \"Baseline_SVC_ts\"\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('data_copy', FunctionTransformer(create_copy_data, validate=False)),\n",
    "    ('getReturns', FunctionTransformer(gettransformedOHLC, validate=False, kw_args={'dividend_column': 'Close', 'divisor_column': 'Close', 'dividend_shift' : 0,\n",
    "                                                                                          'divisor_shift' : 1, 'return_column': 'Returns' })),\n",
    "    ('getReturns_lag1_df', FunctionTransformer(gettransformedOHLC_df, validate=False, kw_args={'dividend_column': 'Close', 'divisor_column': 'Close', 'dividend_shift' : 1,\n",
    "                                                                                          'divisor_shift' : 2, 'column_suffix' : '_Returns_lag1' })),\n",
    "    ('filter_by_symbol', FunctionTransformer(filter_by_symbol, validate=False, kw_args={'symbol': '^SPX'})),\n",
    "    ('apply_simpleCat', FunctionTransformer(apply_simpleCat, validate=False, kw_args={'column_name': 'Returns'})),\n",
    "    ('delete_nan', FunctionTransformer(delete_nan, validate=False)),\n",
    "    ('delete_OHLC', FunctionTransformer(delete_OHLC, validate=False)),\n",
    "    ('split_data_train_val', FunctionTransformer(split_data_train_val,\n",
    "     kw_args={'start_date_train': '2015-01-01', 'end_date_train': '2022-12-31', 'start_date_val': '2023-01-01', 'end_date_val': '2023-12-31'}))\n",
    "])\n",
    "\n",
    "locals()[f\"model_data_train_{strategy}\"], locals()[f\"model_data_val_{strategy}\"] = pipeline.fit_transform(df_Ticker)\n",
    "locals()[f\"x_data_{strategy}\"], locals()[f\"y_data_{strategy}\"], locals()[f\"eval_data_{strategy}\"] = prepare_model_data(locals()[f\"model_data_train_{strategy}\"], 'Returns', 'ReturnsCat')\n",
    "locals()[f\"model_data_train_eval_data_{strategy}\"], locals()[f\"model_{strategy}\"] = train_classifier_ts(locals()[f\"x_data_{strategy}\"], locals()[f\"y_data_{strategy}\"],locals()[f\"eval_data_{strategy}\"], 10, 250)\n",
    "locals()[f\"Evaluation_report_train_{strategy}\"] = Evaluation_generation(locals()[f\"model_data_train_eval_data_{strategy}\"], 'pred', 'ReturnsCat', 'Returns')\n",
    "\n",
    "locals()[f\"x_data_val_{strategy}\"], locals()[f\"y_data_val_{strategy}\"], locals()[f\"eval_data_val_{strategy}\"] = prepare_model_data(locals()[f\"model_data_val_{strategy}\"], 'Returns', 'ReturnsCat')\n",
    "locals()[f\"model_data_val_eval_data_{strategy}\"] = evaluate_classifier_ts(locals()[f\"x_data_val_{strategy}\"], locals()[f\"eval_data_val_{strategy}\"], locals()[f\"model_{strategy}\"])\n",
    "locals()[f\"Evaluation_report_val_{strategy}\"] = Evaluation_generation(locals()[f\"model_data_val_eval_data_{strategy}\"], 'pred', 'ReturnsCat', 'Returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data Evaluation (2015-2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Metric         Value\n",
      "0                    Overview      Overview\n",
      "1                    Accuracy         0.504\n",
      "2                   Precision      0.538462\n",
      "3                         NPV      0.432099\n",
      "4              Return pct lin      13.55357\n",
      "5         Trade Profit Factor      0.182774\n",
      "6               Average_Trade      0.054214\n",
      "7          Average Trade Long      0.106823\n",
      "8         Average Trade Short     -0.055549\n",
      "9                Total Trades           250\n",
      "10      Percent in the Market           1.0\n",
      "11                Long Trades   Long Trades\n",
      "12         Total Winners Long            91\n",
      "13                  Precision      0.538462\n",
      "14                 Long Ratio         0.548\n",
      "15             Return pc long     18.053046\n",
      "16         Profit Factor Long      0.383445\n",
      "17         Average Trade Long      0.106823\n",
      "18          Avergage Win Long       0.71576\n",
      "19          Average Loss Long     -0.603604\n",
      "20           Largest Win Long      2.284078\n",
      "21          Total Losers Long            78\n",
      "22          Largest Loss Long     -2.004123\n",
      "23               Short Trades  Short Trades\n",
      "24        Total Winners Short            35\n",
      "25  Negative Predictive Value      0.432099\n",
      "26                Short Ratio         0.452\n",
      "27           Return pct Short     -4.499476\n",
      "28        Profit Factor Short     -0.166194\n",
      "29        Average Trade Short     -0.055549\n",
      "30          Average Win Short      0.644974\n",
      "31         Average Loss Short     -0.588556\n",
      "32          Largest Win Short      1.581086\n",
      "33         Total Losers Short            46\n",
      "34         Largest Loss Short      -1.89184\n",
      "35              Total Winners           126\n",
      "36                    General       General\n",
      "37                   Accuracy         0.504\n",
      "38               Total Losers           124\n"
     ]
    }
   ],
   "source": [
    "print(locals()[f\"Evaluation_report_train_{strategy}\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Data Validation Set (2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Metric         Value\n",
      "0                    Overview      Overview\n",
      "1                    Accuracy         0.516\n",
      "2                   Precision      0.545977\n",
      "3                         NPV      0.447368\n",
      "4              Return pct lin      8.741347\n",
      "5         Trade Profit Factor      0.114175\n",
      "6               Average_Trade      0.034965\n",
      "7          Average Trade Long      0.089925\n",
      "8         Average Trade Short     -0.090863\n",
      "9                Total Trades           250\n",
      "10      Percent in the Market           1.0\n",
      "11                Long Trades   Long Trades\n",
      "12         Total Winners Long            95\n",
      "13                  Precision      0.545977\n",
      "14                 Long Ratio         0.548\n",
      "15             Return pc long     15.646935\n",
      "16         Profit Factor Long      0.321521\n",
      "17         Average Trade Long      0.089925\n",
      "18          Avergage Win Long      0.676972\n",
      "19          Average Loss Long     -0.616017\n",
      "20           Largest Win Long      2.284078\n",
      "21          Total Losers Long            79\n",
      "22          Largest Loss Long     -2.004123\n",
      "23               Short Trades  Short Trades\n",
      "24        Total Winners Short            34\n",
      "25  Negative Predictive Value      0.447368\n",
      "26                Short Ratio         0.452\n",
      "27           Return pct Short     -6.905588\n",
      "28        Profit Factor Short     -0.247553\n",
      "29        Average Trade Short     -0.090863\n",
      "30          Average Win Short      0.617349\n",
      "31         Average Loss Short     -0.664177\n",
      "32          Largest Win Short      1.581086\n",
      "33         Total Losers Short            42\n",
      "34         Largest Loss Short      -1.89184\n",
      "35              Total Winners           129\n",
      "36                    General       General\n",
      "37                   Accuracy         0.516\n",
      "38               Total Losers           121\n"
     ]
    }
   ],
   "source": [
    "print(locals()[f\"Evaluation_report_val_{strategy}\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = \"Feature_Selection_kbest\"\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('data_copy', FunctionTransformer(create_copy_data, validate=False)),\n",
    "    ('getReturns', FunctionTransformer(gettransformedOHLC, validate=False, kw_args={'dividend_column': 'Close', 'divisor_column': 'Close', 'dividend_shift' : 0,\n",
    "                                                                                          'divisor_shift' : 1, 'return_column': 'Returns' })),\n",
    "    ('getReturns_lag1_df', FunctionTransformer(gettransformedOHLC_df, validate=False, kw_args={'dividend_column': 'Close', 'divisor_column': 'Close', 'dividend_shift' : 1,\n",
    "                                                                                          'divisor_shift' : 2, 'column_suffix' : '_Returns_lag1' })),\n",
    "    ('filter_by_symbol', FunctionTransformer(filter_by_symbol, validate=False, kw_args={'symbol': '^SPX'})),\n",
    "    ('apply_simpleCat', FunctionTransformer(apply_simpleCat, validate=False, kw_args={'column_name': 'Returns'})),\n",
    "    ('delete_nan', FunctionTransformer(delete_nan, validate=False)),\n",
    "    ('delete_OHLC', FunctionTransformer(delete_OHLC, validate=False)),\n",
    "    ('split_data_train_val', FunctionTransformer(split_data_train_val,\n",
    "     kw_args={'start_date_train': '2015-01-01', 'end_date_train': '2022-12-31', 'start_date_val': '2023-01-01', 'end_date_val': '2023-12-31'}))\n",
    "])\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import f_classif\n",
    "locals()[f\"model_data_train_{strategy}\"], locals()[f\"model_data_val_{strategy}\"] = pipeline.fit_transform(df_Ticker)\n",
    "locals()[f\"x_data_{strategy}\"], locals()[f\"y_data_{strategy}\"], locals()[f\"eval_data_{strategy}\"] = prepare_model_data(locals()[f\"model_data_train_{strategy}\"], 'Returns', 'ReturnsCat') \n",
    "fs = SelectKBest(score_func=f_classif, k=70)\n",
    "x_data_selected = fs.fit_transform(locals()[f\"x_data_{strategy}\"], locals()[f\"y_data_{strategy}\"])\n",
    "selected_feature_indices = fs.get_support(indices=True)\n",
    "feature_names = list(locals()[f\"x_data_{strategy}\"].columns)\n",
    "top_features = [feature_names[i] for i in selected_feature_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset_SVC_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = \"Subset_SVC_ts\"\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('data_copy', FunctionTransformer(create_copy_data, validate=False)),\n",
    "    ('getReturns', FunctionTransformer(gettransformedOHLC, validate=False, kw_args={'dividend_column': 'Close', 'divisor_column': 'Close', 'dividend_shift' : 0,\n",
    "                                                                                          'divisor_shift' : 1, 'return_column': 'Returns' })),\n",
    "    ('getReturns_lag1_df', FunctionTransformer(gettransformedOHLC_df, validate=False, kw_args={'dividend_column': 'Close', 'divisor_column': 'Close', 'dividend_shift' : 1,\n",
    "                                                                                          'divisor_shift' : 2, 'column_suffix' : '_Returns_lag1' })),\n",
    "    ('filter_by_symbol', FunctionTransformer(filter_by_symbol, validate=False, kw_args={'symbol': '^SPX'})),\n",
    "    ('apply_simpleCat', FunctionTransformer(apply_simpleCat, validate=False, kw_args={'column_name': 'Returns'})),\n",
    "    ('delete_nan', FunctionTransformer(delete_nan, validate=False)),\n",
    "    ('delete_OHLC', FunctionTransformer(delete_OHLC, validate=False)),\n",
    "    ('split_data_train_val', FunctionTransformer(split_data_train_val,\n",
    "     kw_args={'start_date_train': '2015-01-01', 'end_date_train': '2022-12-31', 'start_date_val': '2023-01-01', 'end_date_val': '2023-12-31'}))\n",
    "])\n",
    "\n",
    "locals()[f\"model_data_train_{strategy}\"], locals()[f\"model_data_val_{strategy}\"] = pipeline.fit_transform(df_Ticker)\n",
    "locals()[f\"x_data_{strategy}\"], locals()[f\"y_data_{strategy}\"], locals()[f\"eval_data_{strategy}\"] = prepare_model_data(locals()[f\"model_data_train_{strategy}\"], 'Returns', 'ReturnsCat')\n",
    "locals()[f\"x_data_{strategy}\"] = locals()[f\"x_data_{strategy}\"][top_features]\n",
    "locals()[f\"model_data_train_eval_data_{strategy}\"], locals()[f\"model_{strategy}\"] = train_classifier_ts(locals()[f\"x_data_{strategy}\"], locals()[f\"y_data_{strategy}\"],locals()[f\"eval_data_{strategy}\"], 10, 250)\n",
    "locals()[f\"Evaluation_report_train_{strategy}\"] = Evaluation_generation(locals()[f\"model_data_train_eval_data_{strategy}\"], 'pred', 'ReturnsCat', 'Returns')\n",
    "\n",
    "locals()[f\"x_data_val_{strategy}\"], locals()[f\"y_data_val_{strategy}\"], locals()[f\"eval_data_val_{strategy}\"] = prepare_model_data(locals()[f\"model_data_val_{strategy}\"], 'Returns', 'ReturnsCat')\n",
    "locals()[f\"x_data_val_{strategy}\"] = locals()[f\"x_data_val_{strategy}\"][top_features]\n",
    "locals()[f\"model_data_val_eval_data_{strategy}\"] = evaluate_classifier_ts(locals()[f\"x_data_val_{strategy}\"], locals()[f\"eval_data_val_{strategy}\"], locals()[f\"model_{strategy}\"])\n",
    "locals()[f\"Evaluation_report_val_{strategy}\"] = Evaluation_generation(locals()[f\"model_data_val_eval_data_{strategy}\"], 'pred', 'ReturnsCat', 'Returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data Evaluation (2015-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Metric         Value\n",
      "0                    Overview      Overview\n",
      "1                    Accuracy      0.521978\n",
      "2                   Precision       0.53918\n",
      "3                         NPV        0.4662\n",
      "4              Return pct lin     43.537207\n",
      "5         Trade Profit Factor      0.064481\n",
      "6               Average_Trade      0.023922\n",
      "7          Average Trade Long      0.043961\n",
      "8         Average Trade Short     -0.041056\n",
      "9                Total Trades          1820\n",
      "10      Percent in the Market           1.0\n",
      "11                Long Trades   Long Trades\n",
      "12         Total Winners Long           750\n",
      "13                  Precision       0.53918\n",
      "14                 Long Ratio      0.537912\n",
      "15             Return pc long     61.150407\n",
      "16         Profit Factor Long       0.11516\n",
      "17         Average Trade Long      0.043961\n",
      "18          Avergage Win Long      0.789537\n",
      "19          Average Loss Long     -0.828396\n",
      "20           Largest Win Long      9.382774\n",
      "21          Total Losers Long           641\n",
      "22          Largest Loss Long    -11.984055\n",
      "23               Short Trades  Short Trades\n",
      "24        Total Winners Short           200\n",
      "25  Negative Predictive Value        0.4662\n",
      "26                Short Ratio      0.462088\n",
      "27           Return pct Short    -17.613199\n",
      "28        Profit Factor Short     -0.122151\n",
      "29        Average Trade Short     -0.041056\n",
      "30          Average Win Short      0.632893\n",
      "31         Average Loss Short     -0.629658\n",
      "32          Largest Win Short       3.59198\n",
      "33         Total Losers Short           229\n",
      "34         Largest Loss Short     -2.615627\n",
      "35              Total Winners           950\n",
      "36                    General       General\n",
      "37                   Accuracy      0.521978\n",
      "38               Total Losers           870\n"
     ]
    }
   ],
   "source": [
    "print(locals()[f\"Evaluation_report_train_{strategy}\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Data Validation Set (2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Metric         Value\n",
      "0                    Overview      Overview\n",
      "1                    Accuracy         0.504\n",
      "2                   Precision      0.538462\n",
      "3                         NPV      0.432099\n",
      "4              Return pct lin      13.55357\n",
      "5         Trade Profit Factor      0.182774\n",
      "6               Average_Trade      0.054214\n",
      "7          Average Trade Long      0.106823\n",
      "8         Average Trade Short     -0.055549\n",
      "9                Total Trades           250\n",
      "10      Percent in the Market           1.0\n",
      "11                Long Trades   Long Trades\n",
      "12         Total Winners Long            91\n",
      "13                  Precision      0.538462\n",
      "14                 Long Ratio         0.548\n",
      "15             Return pc long     18.053046\n",
      "16         Profit Factor Long      0.383445\n",
      "17         Average Trade Long      0.106823\n",
      "18          Avergage Win Long       0.71576\n",
      "19          Average Loss Long     -0.603604\n",
      "20           Largest Win Long      2.284078\n",
      "21          Total Losers Long            78\n",
      "22          Largest Loss Long     -2.004123\n",
      "23               Short Trades  Short Trades\n",
      "24        Total Winners Short            35\n",
      "25  Negative Predictive Value      0.432099\n",
      "26                Short Ratio         0.452\n",
      "27           Return pct Short     -4.499476\n",
      "28        Profit Factor Short     -0.166194\n",
      "29        Average Trade Short     -0.055549\n",
      "30          Average Win Short      0.644974\n",
      "31         Average Loss Short     -0.588556\n",
      "32          Largest Win Short      1.581086\n",
      "33         Total Losers Short            46\n",
      "34         Largest Loss Short      -1.89184\n",
      "35              Total Winners           126\n",
      "36                    General       General\n",
      "37                   Accuracy         0.504\n",
      "38               Total Losers           124\n"
     ]
    }
   ],
   "source": [
    "print(locals()[f\"Evaluation_report_val_{strategy}\"] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
